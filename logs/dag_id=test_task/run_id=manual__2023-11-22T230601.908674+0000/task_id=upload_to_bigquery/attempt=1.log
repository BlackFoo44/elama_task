[2023-11-22T23:06:07.587+0000] {taskinstance.py:1171} INFO - Dependencies all met for <TaskInstance: test_task.upload_to_bigquery manual__2023-11-22T23:06:01.908674+00:00 [queued]>
[2023-11-22T23:06:07.594+0000] {taskinstance.py:1171} INFO - Dependencies all met for <TaskInstance: test_task.upload_to_bigquery manual__2023-11-22T23:06:01.908674+00:00 [queued]>
[2023-11-22T23:06:07.594+0000] {taskinstance.py:1368} INFO - 
--------------------------------------------------------------------------------
[2023-11-22T23:06:07.594+0000] {taskinstance.py:1369} INFO - Starting attempt 1 of 5
[2023-11-22T23:06:07.595+0000] {taskinstance.py:1370} INFO - 
--------------------------------------------------------------------------------
[2023-11-22T23:06:07.605+0000] {taskinstance.py:1389} INFO - Executing <Task(PythonOperator): upload_to_bigquery> on 2023-11-22 23:06:01.908674+00:00
[2023-11-22T23:06:07.608+0000] {standard_task_runner.py:52} INFO - Started process 244 to run task
[2023-11-22T23:06:07.610+0000] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'test_task', 'upload_to_bigquery', 'manual__2023-11-22T23:06:01.908674+00:00', '--job-id', '216', '--raw', '--subdir', 'DAGS_FOLDER/add_data_dag.py', '--cfg-path', '/tmp/tmpxb2nct77', '--error-file', '/tmp/tmplzd8btut']
[2023-11-22T23:06:07.611+0000] {standard_task_runner.py:80} INFO - Job 216: Subtask upload_to_bigquery
[2023-11-22T23:06:07.661+0000] {task_command.py:371} INFO - Running <TaskInstance: test_task.upload_to_bigquery manual__2023-11-22T23:06:01.908674+00:00 [running]> on host 54bfe75eb29c
[2023-11-22T23:06:07.716+0000] {taskinstance.py:1583} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=***@example.com
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=test_task
AIRFLOW_CTX_TASK_ID=upload_to_bigquery
AIRFLOW_CTX_EXECUTION_DATE=2023-11-22T23:06:01.908674+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2023-11-22T23:06:01.908674+00:00
[2023-11-22T23:06:07.722+0000] {add_data.py:68} INFO - <google.oauth2.service_account.Credentials object at 0x7fa694cd1b10>
[2023-11-22T23:06:07.727+0000] {log.py:128} INFO - select pg_catalog.version()
[2023-11-22T23:06:07.727+0000] {log.py:128} INFO - [raw sql] {}
[2023-11-22T23:06:07.728+0000] {log.py:128} INFO - select current_schema()
[2023-11-22T23:06:07.728+0000] {log.py:128} INFO - [raw sql] {}
[2023-11-22T23:06:07.729+0000] {log.py:128} INFO - show standard_conforming_strings
[2023-11-22T23:06:07.729+0000] {log.py:128} INFO - [raw sql] {}
[2023-11-22T23:06:07.729+0000] {log.py:128} INFO - BEGIN (implicit)
[2023-11-22T23:06:07.730+0000] {log.py:128} INFO - 
                SELECT * FROM test_1;
                
[2023-11-22T23:06:07.730+0000] {log.py:128} INFO - [generated in 0.00029s] {}
[2023-11-22T23:06:07.732+0000] {add_data.py:55} INFO - Данные успешно загружены для передачи в BigQuery.
[2023-11-22T23:06:07.732+0000] {log.py:128} INFO - ROLLBACK
[2023-11-22T23:06:11.006+0000] {add_data.py:80} INFO - Данные успешно загружены в BigQuery: mytestproject-343412.1234567890.my_table
[2023-11-22T23:06:11.006+0000] {python.py:173} INFO - Done. Returned value was: None
[2023-11-22T23:06:11.020+0000] {taskinstance.py:1412} INFO - Marking task as SUCCESS. dag_id=test_task, task_id=upload_to_bigquery, execution_date=20231122T230601, start_date=20231122T230607, end_date=20231122T230611
[2023-11-22T23:06:11.034+0000] {local_task_job.py:156} INFO - Task exited with return code 0
[2023-11-22T23:06:11.062+0000] {local_task_job.py:279} INFO - 0 downstream tasks scheduled from follow-on schedule check
